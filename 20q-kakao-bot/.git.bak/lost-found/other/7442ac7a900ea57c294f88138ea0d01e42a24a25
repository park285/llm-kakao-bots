package party.qwer.twentyq.service

import jakarta.annotation.PostConstruct
import jakarta.annotation.PreDestroy
import kr.co.shineware.nlp.komoran.constant.DEFAULT_MODEL
import kr.co.shineware.nlp.komoran.core.Komoran
import kr.co.shineware.nlp.komoran.model.KomoranResult
import org.slf4j.LoggerFactory
import org.springframework.stereotype.Service

@Service
class KomoranService(
    private val spellChecker: SpellChecker,
) {
    companion object {
        private const val ERROR_NOT_INITIALIZED = "KOMORAN not initialized"
        private val log = LoggerFactory.getLogger(KomoranService::class.java)
        private val INCOMPLETE_HANGUL = Regex("[ㄱ-ㅎㅏ-ㅣ]{2,}")
        private val EMOTICON_PATTERN = Regex(".*[ㅋㅎ]{2,}.*")

        fun scoreUnknownTokens(tokens: List<Token>): Double {
            val unknownRatio = tokens.count { it.tag.startsWith("UNK") }.toDouble() / tokens.size
            return when {
                unknownRatio > 0.6 -> 0.4
                unknownRatio > 0.4 -> 0.3
                unknownRatio > 0.2 -> 0.1
                else -> 0.0
            }
        }

        fun scoreTokenLength(tokens: List<Token>): Double {
            val avgTokenLength = tokens.map { it.length }.average()
            return when {
                avgTokenLength < 0.6 -> 0.3
                avgTokenLength < 0.8 -> 0.2
                avgTokenLength < 1.0 -> 0.1
                else -> 0.0
            }
        }

        fun scoreIncompleteHangul(text: String): Double {
            val hangulCount = text.count { it in '가'..'힣' }
            val hangulRatio = hangulCount.toDouble() / text.length
            val hasIncompleteHangul = text.contains(INCOMPLETE_HANGUL) && !text.matches(EMOTICON_PATTERN)
            return if (hasIncompleteHangul) {
                when {
                    hangulRatio < 0.2 -> 0.2
                    hangulRatio < 0.4 -> 0.1
                    else -> 0.0
                }
            } else {
                0.0
            }
        }

        fun scoreContentRatio(tokens: List<Token>): Double {
            val contentWords =
                tokens.count {
                    it.tag.startsWith("NN") || it.tag.startsWith("VV") || it.tag.startsWith("VA") ||
                        it.tag == "NR"
                }
            val contentRatio = contentWords.toDouble() / tokens.size
            return if (contentRatio < 0.15 && tokens.size > 3) 0.15 else 0.0
        }
    }

    private var komoran: Komoran? = null

    @PostConstruct
    @Suppress("TooGenericExceptionCaught")
    fun init() {
        try {
            log.info("Initializing KOMORAN (ModelType: STABLE)")
            komoran = Komoran(DEFAULT_MODEL.STABLE)
            log.info("KOMORAN initialized successfully")
        } catch (e: Exception) {
            log.error("Failed to initialize KOMORAN: {}", e.message, e)
            throw IllegalStateException("KOMORAN initialization failed", e)
        }
    }

    @PreDestroy
    fun destroy() {
        log.info("Destroying KomoranService")
        komoran = null
    }

    data class Token(
        val form: String,
        val tag: String,
        val position: Int,
        val length: Int,
    )

    /**
     * 맞춤법 교정 + 형태소 분석 (기본 메서드)
     * 레거시 제거: 항상 맞춤법 교정 후 분석
     */
    suspend fun analyze(
        text: String,
        topN: Int = 1,
    ): List<Token> {
        val corrected = spellChecker.correct(text)
        return analyzeInternal(corrected, topN)
    }

    // SpellCheck 없이 분석 (내부 생성 텍스트용 - 힌트, secretJson 등)
    fun analyzeWithoutSpellCheck(
        text: String,
        topN: Int = 1,
    ): List<Token> = analyzeInternal(text, topN)

    // 내부 형태소 분석 (맞춤법 교정 없이)
    @Suppress("ReturnCount", "TooGenericExceptionCaught", "UnusedParameter")
    private fun analyzeInternal(
        text: String,
        topN: Int = 1,
    ): List<Token> {
        val instance = checkNotNull(komoran) { ERROR_NOT_INITIALIZED }

        try {
            val result: KomoranResult = instance.analyze(text)
            val tokens = result.tokenList ?: return emptyList()

            return tokens.map { token ->
                Token(
                    form = token.morph,
                    tag = token.pos,
                    position = token.beginIndex,
                    length = token.endIndex - token.beginIndex,
                )
            }
        } catch (e: Exception) {
            log.error("Failed to analyze text: {}", e.message)
            return emptyList()
        }
    }

    suspend fun extractNouns(text: String): List<String> {
        val corrected = spellChecker.correct(text)
        val instance = checkNotNull(komoran) { ERROR_NOT_INITIALIZED }
        return instance.analyze(corrected).nouns
    }

    suspend fun extractVerbs(text: String): List<String> {
        val corrected = spellChecker.correct(text)
        val instance = checkNotNull(komoran) { ERROR_NOT_INITIALIZED }
        return instance.analyze(corrected).getMorphesByTags("VV", "VA", "NR")
    }

    @Suppress("TooGenericExceptionCaught")
    suspend fun calculateAnomalyScore(text: String): Double {
        if (text.length < 3) return 0.0
        var score = 0.5
        try {
            val tokens = analyze(text)
            if (tokens.isEmpty()) {
                score = 0.8
            } else {
                val s =
                    scoreUnknownTokens(tokens) +
                        scoreTokenLength(tokens) +
                        scoreIncompleteHangul(text) +
                        scoreContentRatio(tokens)
                score = s.coerceIn(0.0, 1.0)
            }
        } catch (e: Exception) {
            log.warn("calculateAnomalyScore failed for text='{}': {}", text.take(50), e.message)
        }
        return score
    }

    data class KiwiHeuristics(
        val numericQuantifier: Boolean,
        val unitNoun: Boolean,
        val boundaryRef: Boolean,
        val comparisonWord: Boolean,
    ) {
        val suspiciousMetaPattern: Boolean
            get() =
                (numericQuantifier && unitNoun) || (boundaryRef && unitNoun) ||
                    (numericQuantifier && comparisonWord)
    }

    @Suppress("TooGenericExceptionCaught")
    suspend fun analyzeHeuristics(text: String): KiwiHeuristics {
        return try {
            val tokens = analyze(text)
            if (tokens.isEmpty()) return KiwiHeuristics(false, false, false, false)

            val numericQuantifier = tokens.any { it.tag == "NR" }
            val unitNouns =
                setOf("글자", "자", "음절", "문자", "토큰", "개", "번", "번째", "회", "차례", "모음", "자음", "초성", "중성", "종성", "받침")
            val unitNoun = tokens.any { it.form in unitNouns }
            val boundaryWords = setOf("처음", "끝", "마지막", "시작", "중간", "가운데", "초성", "중성", "종성", "받침")
            val boundaryRef = tokens.any { it.form in boundaryWords }
            val comparisonWords = setOf("이상", "이하", "초과", "미만", "넘", "이내")
            val comparison = tokens.any { it.form in comparisonWords }

            KiwiHeuristics(numericQuantifier, unitNoun, boundaryRef, comparison)
        } catch (e: Exception) {
            log.warn("analyzeHeuristics failed for text='{}': {}", text.take(50), e.message)
            KiwiHeuristics(false, unitNoun = false, boundaryRef = false, comparisonWord = false)
        }
    }
}
